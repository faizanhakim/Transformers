{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'D:\\\\My Work\\\\Final Year Project\\\\Transformer\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Faizan\\AppData\\Local\\Temp\\ipykernel_14892\\2610695767.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "C:\\Users\\Faizan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from nltk.corpus import wordnet as wn, stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as nmi_score\n",
    "from sklearn.metrics import adjusted_rand_score as ari_score\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pickle\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from utils.Encoder import Encoder\n",
    "\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.cluster._kmeans\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.feature_extraction.text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_content = []  # all the content in the document\n",
    "doc_name = []  # name of the document\n",
    "files_path = []  # path to the documents\n",
    "lexical_chain = []  # list of lexical chains from each document\n",
    "total_features = []  # total number of features. 1652\n",
    "final_training_Features = []\n",
    "corpus = []\n",
    "doc_list_sequence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seeds(seed):\n",
    "   os.environ['PYTHONHASHSEED']=str(seed)\n",
    "   torch.manual_seed(seed)\n",
    "   np.random.seed(seed)\n",
    "   random.seed(seed)\n",
    "\n",
    "\n",
    "def ReadDocuments(dir_name):\n",
    "    for Path in os.listdir(dir_name):\n",
    "        file_p = os.path.join(dir_name, Path)\n",
    "        with open(file_p, \"r\") as file:\n",
    "            FileContents = file.read()\n",
    "            doc_content.append(FileContents.lower())\n",
    "            doc_name.append(Path)\n",
    "            files_path.append(file_p)\n",
    "\n",
    "def Purity_Score(label_seq, pred_labels):\n",
    "    # Calculate the confusion matrix to compare true labels and cluster assignments\n",
    "    confusion = confusion_matrix(label_seq, pred_labels)\n",
    "    # Calculate the purity\n",
    "    purity = np.sum(np.max(confusion, axis=0)) / np.sum(confusion)\n",
    "    return purity\n",
    "\n",
    "def Evaluate(X, true_labels, predicted_labels):\n",
    "    purity = Purity_Score(true_labels, predicted_labels)\n",
    "    silhouette = silhouette_score(X, predicted_labels, metric='euclidean')\n",
    "    ari = ari_score(true_labels, predicted_labels)\n",
    "    nmi = nmi_score(true_labels, predicted_labels)\n",
    "    \n",
    "    print(f\"Purity: {purity}\")\n",
    "    print(f\"Silhouette Score: {silhouette}\")\n",
    "    print(f\"ARI Score: {ari}\")\n",
    "    print(f\"NMI Score: {nmi}\")\n",
    "\n",
    "def SaveFeatures(X, file_name):\n",
    "    pickle_path = open(file_name, 'wb')\n",
    "    pickle.dump(X, pickle_path)\n",
    "    pickle_path.close()\n",
    "\n",
    "def ReadFeatures(file_name):\n",
    "    pickle_read = open(file_name, 'rb')\n",
    "    x = pickle.load(pickle_read)\n",
    "    pickle_read.close()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"DOC50_Features/DOC50_TFIDF_Features.pkl\"\n",
    "x = ReadFeatures(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3885)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(shape=(1, x.size()[0], x.size()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50, 3885])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 3885\n",
    "num_heads = 1\n",
    "drop_prob = 0.1\n",
    "batch_size = 1\n",
    "max_sequence_length = 50\n",
    "ffn_hidden = 2048\n",
    "num_layers = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_random_seeds(42)\n",
    "encoder = Encoder(d_model=d_model, ffn_hidden=ffn_hidden, num_heads=num_heads, drop_prob=drop_prob, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0265, 0.0000,  ..., 0.0339, 0.0000, 0.0339],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]])\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.1081, -0.8454,  1.0193,  ..., -0.7751,  0.0484,  0.4439],\n",
      "         [-0.3943,  1.0203,  0.8510,  ...,  1.1748,  0.1908,  1.3690],\n",
      "         [ 0.0945, -0.4769,  1.2139,  ..., -0.3050,  0.1550,  0.4473],\n",
      "         ...,\n",
      "         [ 0.2678, -0.2911,  1.3415,  ..., -0.7485,  0.3273,  0.0027],\n",
      "         [ 0.2717, -0.0565,  1.0506,  ..., -0.3180,  0.1337,  0.2724],\n",
      "         [ 0.3743, -0.1403,  0.8966,  ..., -0.5687,  0.1590,  0.1582]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.0096, -0.4541,  0.5646,  ..., -0.3404,  0.8090,  0.4711],\n",
      "         [-0.3353,  0.9904,  1.3544,  ...,  1.3940,  0.2906,  1.5027],\n",
      "         [ 0.3062, -0.2712,  1.6844,  ...,  0.2570,  0.0981,  0.3314],\n",
      "         ...,\n",
      "         [ 0.1156, -0.4394,  1.4182,  ...,  0.1255,  0.5581,  0.1830],\n",
      "         [ 0.0697, -0.1582,  1.2648,  ..., -0.2989,  0.7318,  0.3808],\n",
      "         [ 0.4071, -0.4945,  1.3887,  ...,  0.0398,  0.8970,  0.5401]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[ 0.1756, -0.6415,  0.6071,  ..., -0.2204,  0.8815,  0.2591],\n",
      "         [ 0.0135,  0.6066,  1.5219,  ...,  1.3810,  0.5597,  1.3991],\n",
      "         [ 0.3730, -0.2577,  1.4669,  ...,  0.0210,  0.4172, -0.1138],\n",
      "         ...,\n",
      "         [ 0.1034, -0.5240,  1.3644,  ..., -0.2489,  0.6374, -0.0928],\n",
      "         [-0.1344, -0.3421,  1.3503,  ..., -0.7953,  1.2893, -0.2267],\n",
      "         [ 0.0189, -0.5827,  1.3152,  ..., -0.4611,  1.1184, -0.0704]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.4518, -0.4065,  1.0325,  ...,  0.4085,  0.8590,  0.2402],\n",
      "         [-0.9301,  0.3532,  1.4370,  ...,  1.6955,  0.1582,  1.1077],\n",
      "         [-0.2342, -0.1725,  1.7437,  ...,  0.5821,  0.1769, -0.6925],\n",
      "         ...,\n",
      "         [-0.7806, -0.4952,  1.7139,  ...,  0.0652,  0.2945, -0.1390],\n",
      "         [-0.8530, -0.8494,  1.2653,  ..., -0.7062,  0.7553, -0.3484],\n",
      "         [-0.8305, -0.8453,  1.3714,  ..., -0.0463,  0.7327, -0.3548]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.2413, -0.2529,  0.7525,  ...,  0.7061,  0.9853,  1.4886],\n",
      "         [-0.7760,  0.4381,  1.1953,  ...,  1.7169,  0.6705,  1.3639],\n",
      "         [ 0.4536,  0.4038,  1.6057,  ...,  0.8320,  0.1816, -0.1978],\n",
      "         ...,\n",
      "         [-0.8051, -0.7766,  1.6176,  ..., -0.3230,  0.4071, -0.0562],\n",
      "         [-0.6008, -0.7098,  1.2308,  ..., -0.4911,  0.3637, -0.2466],\n",
      "         [-0.8696, -0.9648,  1.3891,  ..., -0.0690,  0.5563, -0.4560]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.4829,  0.0233,  0.6647,  ...,  0.3484,  0.9881,  1.0064],\n",
      "         [-0.6072,  0.8408,  1.1363,  ...,  1.7546,  0.5364,  0.7201],\n",
      "         [ 0.1772,  0.5668,  1.6624,  ...,  0.6285, -0.2348, -0.3183],\n",
      "         ...,\n",
      "         [-0.6583, -0.5055,  1.3607,  ..., -0.3887,  0.3495, -0.6740],\n",
      "         [-0.6917, -0.3349,  1.1204,  ..., -0.2898,  0.1102, -1.1787],\n",
      "         [-0.6000, -0.8350,  1.4292,  ..., -0.2821,  0.3348, -0.6847]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.3583,  0.3479,  0.1906,  ..., -0.4214,  0.8986,  1.0432],\n",
      "         [-1.8054,  0.6746,  0.5674,  ...,  1.2726,  0.4406,  0.6787],\n",
      "         [-0.5572,  0.5221,  1.5476,  ...,  0.0445, -0.2765,  0.1096],\n",
      "         ...,\n",
      "         [-0.9854, -0.5754,  0.5749,  ..., -0.8777,  0.5592, -0.2563],\n",
      "         [-1.2044, -0.2214,  0.5151,  ..., -0.7881, -0.1057, -1.2852],\n",
      "         [-1.2247, -0.8317,  1.3972,  ..., -0.8849,  0.3841, -0.5315]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.7499,  0.4993,  0.3450,  ..., -0.3057,  1.4681,  1.6130],\n",
      "         [-1.8465,  0.6488,  0.7396,  ...,  1.1864,  0.8495,  1.3352],\n",
      "         [-0.1342,  0.2923,  1.5696,  ...,  0.0748,  0.1171,  0.7064],\n",
      "         ...,\n",
      "         [-1.1492, -0.7898,  1.3594,  ..., -0.7278,  0.9569,  0.2221],\n",
      "         [-1.4182, -0.7802,  1.3657,  ..., -0.7684,  0.3780, -0.4183],\n",
      "         [-1.1548, -1.0399,  1.7204,  ..., -0.8992,  0.8699,  0.3949]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.8345,  0.0769,  0.6554,  ..., -0.5891,  0.4066,  1.5647],\n",
      "         [-2.1023,  0.4150,  0.8549,  ...,  0.9446,  0.6938,  0.6770],\n",
      "         [-0.3080,  0.4654,  1.9625,  ...,  0.2126,  0.1063,  0.1359],\n",
      "         ...,\n",
      "         [-1.2311, -0.7732,  1.4013,  ..., -0.6157,  0.7271, -0.0283],\n",
      "         [-1.0353, -1.0416,  2.0344,  ..., -0.5645,  0.5698, -0.8218],\n",
      "         [-0.9620, -0.9387,  2.1858,  ..., -0.6886,  0.5874,  0.0316]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.3509,  0.2444,  0.7590,  ..., -0.9461,  0.4800,  1.1562],\n",
      "         [-1.7246,  0.2415,  0.9245,  ...,  0.9342,  0.6482,  0.2020],\n",
      "         [ 0.5860,  0.4911,  1.6022,  ...,  0.2442, -0.1941, -0.2820],\n",
      "         ...,\n",
      "         [-0.5324, -0.3039,  1.1801,  ..., -0.8407,  0.6365, -0.2368],\n",
      "         [-0.8915, -1.2099,  1.6806,  ..., -1.0055,  0.5370, -0.9663],\n",
      "         [-0.6213, -0.9747,  1.8838,  ..., -0.9911,  0.5572, -0.3865]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.4787,  0.4670,  0.6245,  ..., -1.2537,  0.5127,  1.6474],\n",
      "         [-1.8021, -0.0607,  1.0216,  ...,  0.7167,  0.4699,  0.3507],\n",
      "         [ 0.4828,  0.3917,  1.7040,  ..., -0.1041, -0.3518,  0.0870],\n",
      "         ...,\n",
      "         [-1.1722, -0.1677,  1.0367,  ..., -1.0781,  0.4328,  0.0318],\n",
      "         [-1.1045, -0.8921,  1.6458,  ..., -1.5171,  0.4262, -0.8912],\n",
      "         [-0.9973, -0.6387,  1.7736,  ..., -1.9530,  0.1185, -0.4896]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.0954,  0.7418,  0.2956,  ..., -1.1862,  0.5819,  1.4715],\n",
      "         [-1.7511,  0.2993,  0.2892,  ...,  1.1434,  0.4551,  0.0486],\n",
      "         [ 0.4116,  1.0377,  1.2964,  ...,  0.1433, -0.1814, -0.1595],\n",
      "         ...,\n",
      "         [-0.2458, -0.2287,  0.7756,  ..., -0.8641,  0.7475, -0.2961],\n",
      "         [-0.6763, -0.8521,  1.2326,  ..., -1.4897,  0.6903, -0.6278],\n",
      "         [-0.1883, -0.2934,  1.3315,  ..., -1.8036,  0.1286, -0.6898]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.1308,  0.5137,  1.0848,  ..., -0.6535,  1.1069,  1.6355],\n",
      "         [-1.5185,  0.5163,  0.7517,  ...,  1.0547,  0.8203,  0.2159],\n",
      "         [ 0.3629,  0.8442,  1.7024,  ...,  0.3604,  0.1275,  0.2125],\n",
      "         ...,\n",
      "         [-0.2175, -0.3065,  1.1624,  ..., -0.8587,  0.7957, -0.7426],\n",
      "         [-0.7629, -0.5400,  1.5347,  ..., -1.6356,  0.4126, -0.5762],\n",
      "         [-0.2688, -0.1661,  1.3584,  ..., -1.8893,  0.5932, -0.4006]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.9761,  0.2943,  0.6857,  ..., -1.1911,  0.9545,  1.3809],\n",
      "         [-1.4554,  0.6565,  0.7374,  ...,  0.3250,  1.0368, -0.0528],\n",
      "         [ 0.4479,  0.5621,  1.9552,  ..., -0.2729,  0.4508, -0.4718],\n",
      "         ...,\n",
      "         [-0.1213, -0.8931,  0.6881,  ..., -1.0062,  0.9866, -1.0728],\n",
      "         [-1.1313, -0.7557,  1.0765,  ..., -1.8420,  0.7005, -0.5390],\n",
      "         [-0.2902, -0.4402,  0.9082,  ..., -2.1254,  0.8921, -0.5832]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.3535, -0.1092,  1.0227,  ..., -1.5146,  0.5905,  1.4649],\n",
      "         [-0.8270,  0.1761,  0.7051,  ...,  0.4712,  0.6008,  0.3638],\n",
      "         [ 0.5528,  0.0471,  1.7349,  ..., -0.8185,  0.3391, -0.2523],\n",
      "         ...,\n",
      "         [-0.1123, -1.3392,  0.6517,  ..., -1.0145,  0.6736, -0.8735],\n",
      "         [-1.2075, -1.0779,  1.0930,  ..., -1.7947,  0.7196, -0.1812],\n",
      "         [-0.4543, -0.4687,  1.0191,  ..., -1.8615,  0.6889, -0.4839]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.0433, -0.4462,  1.1851,  ..., -1.7996,  0.6619,  1.5544],\n",
      "         [-1.5310, -0.2706,  0.5402,  ...,  0.1855,  0.6755,  0.3883],\n",
      "         [-0.4147, -0.1824,  1.5276,  ..., -1.1541,  0.0348, -0.1548],\n",
      "         ...,\n",
      "         [-0.2980, -1.7121,  0.3394,  ..., -0.6182,  0.8043, -0.5606],\n",
      "         [-1.4565, -1.5418,  0.7571,  ..., -1.6380,  0.4164,  0.0532],\n",
      "         [-0.8012, -1.0012,  0.8050,  ..., -1.8152,  0.8179, -0.4070]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.7802, -0.0678,  1.2890,  ..., -1.7831,  0.4434,  2.5618],\n",
      "         [-1.2282, -0.2682,  0.6133,  ...,  0.4366,  0.6847,  1.2100],\n",
      "         [-0.4226, -0.2564,  1.5428,  ..., -0.9586, -0.1081,  0.4219],\n",
      "         ...,\n",
      "         [-0.1187, -1.5780,  0.3737,  ..., -0.0223,  0.9191, -0.2444],\n",
      "         [-0.9771, -1.4405,  0.8924,  ..., -1.0066,  0.2421, -0.0077],\n",
      "         [-0.8552, -1.0563,  0.9125,  ..., -1.7759,  0.6112, -0.5047]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.5602, -0.1341,  1.3534,  ..., -0.6600,  0.5178,  2.5584],\n",
      "         [-2.1033,  0.0123,  0.7518,  ...,  0.9428,  0.9080,  1.4290],\n",
      "         [-1.0540, -0.1621,  1.5452,  ..., -0.4067, -0.3210,  0.8971],\n",
      "         ...,\n",
      "         [-0.3765, -0.5299,  0.5541,  ...,  0.2697,  1.0079, -0.2897],\n",
      "         [-1.1894, -0.6309,  0.6334,  ..., -0.6897,  0.2205,  0.1116],\n",
      "         [-0.8837, -0.2914,  0.5617,  ..., -1.1980,  0.9011, -0.3874]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-2.2563,  0.4727,  2.4538,  ..., -0.1693,  0.1613,  2.4216],\n",
      "         [-2.7481,  0.4999,  1.5347,  ...,  1.0658,  0.5001,  1.4643],\n",
      "         [-1.8299,  0.5410,  1.8937,  ..., -0.0504, -0.7951,  0.8051],\n",
      "         ...,\n",
      "         [-1.0640,  0.1275,  0.7136,  ...,  0.0348,  0.6179, -0.2254],\n",
      "         [-1.3813, -0.4551,  0.9856,  ..., -0.2896,  0.0379,  0.0823],\n",
      "         [-1.0710, -0.0539,  0.9984,  ..., -1.2520,  0.6531, -0.7135]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.6331,  0.4961,  2.6181,  ...,  0.0735,  0.1921,  1.5945],\n",
      "         [-2.0504,  0.7175,  1.8063,  ...,  1.2840,  0.6064,  0.9365],\n",
      "         [-1.2254,  0.5235,  1.9434,  ..., -0.1203, -0.8041,  0.3372],\n",
      "         ...,\n",
      "         [-0.5904,  0.0928,  0.7009,  ...,  0.5100,  0.5626, -0.5875],\n",
      "         [-0.6754, -0.5991,  0.9492,  ..., -0.1930,  0.0844, -0.3614],\n",
      "         [-0.6424, -0.1792,  1.0364,  ..., -0.7921,  0.5372, -1.1374]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.4009,  0.1597,  2.4166,  ..., -0.1951,  0.7494,  1.2324],\n",
      "         [-1.8289, -0.1235,  1.6263,  ...,  1.0516,  1.0085,  0.7680],\n",
      "         [-0.8602, -0.4405,  2.0420,  ..., -0.1385, -0.3638,  0.5640],\n",
      "         ...,\n",
      "         [-0.4651, -0.3532,  0.4744,  ...,  0.3836,  0.9031, -0.5509],\n",
      "         [-0.2806, -1.2036,  0.8664,  ..., -0.5129,  0.3638, -0.5188],\n",
      "         [-0.1267, -0.9646,  0.9726,  ..., -0.9918,  0.3002, -0.7695]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.4738e+00, -9.2494e-01,  2.2253e+00,  ..., -3.7360e-02,\n",
      "           3.5951e-01,  6.7976e-01],\n",
      "         [-2.1446e+00, -1.1271e+00,  1.3981e+00,  ...,  1.0131e+00,\n",
      "           6.8423e-01,  4.3672e-01],\n",
      "         [-9.2706e-01, -9.2930e-01,  1.7996e+00,  ..., -1.6420e-01,\n",
      "          -3.0436e-01,  1.2062e-01],\n",
      "         ...,\n",
      "         [-5.0244e-01, -3.1211e-01,  1.4706e-01,  ..., -2.6659e-01,\n",
      "           1.1649e-01, -1.0351e+00],\n",
      "         [-6.4663e-01, -2.0880e+00,  6.7358e-01,  ..., -9.0673e-01,\n",
      "          -2.0121e-03, -8.0305e-01],\n",
      "         [-4.8232e-01, -1.6625e+00,  5.7930e-01,  ..., -1.2552e+00,\n",
      "           8.4743e-02, -9.6959e-01]]], grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.6191, -0.1312,  2.5338,  ...,  0.0629,  0.1714,  0.7552],\n",
      "         [-1.7726, -0.5493,  1.7714,  ...,  0.9114,  0.6715,  0.4120],\n",
      "         [-1.1500, -0.2034,  1.9236,  ..., -0.3554, -0.2305,  0.2490],\n",
      "         ...,\n",
      "         [-0.9954,  0.2100,  0.4611,  ..., -0.3777,  0.3380, -0.8914],\n",
      "         [-1.2150, -0.5728,  0.6530,  ..., -0.9031, -0.0034, -0.6433],\n",
      "         [-0.8995, -1.1475,  0.5720,  ..., -1.2150,  0.3482, -0.7258]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.6263, -0.6009,  3.0520,  ..., -0.0912,  0.1220,  0.0791],\n",
      "         [-1.1187, -0.9101,  2.0598,  ...,  0.6417,  0.6788, -0.4274],\n",
      "         [-1.0751, -0.6041,  2.2323,  ..., -0.9489, -0.2886, -0.5550],\n",
      "         ...,\n",
      "         [-1.1556, -0.0479,  0.8894,  ..., -0.6909,  0.6636, -1.5158],\n",
      "         [-1.0407, -0.7023,  1.1328,  ..., -0.7631,  0.0072, -1.0180],\n",
      "         [-1.5240, -1.5096,  0.5775,  ..., -1.1225,  0.4908, -1.6609]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.6772, -0.6909,  2.7906,  ...,  0.0268,  0.0074,  0.1218],\n",
      "         [-1.0325, -0.6973,  1.5059,  ...,  0.5378,  0.4764, -0.7274],\n",
      "         [-0.8885, -0.8625,  1.5030,  ..., -1.0085, -0.4984, -0.6250],\n",
      "         ...,\n",
      "         [-0.7509, -0.2189,  0.3055,  ..., -0.7769,  0.5915, -1.9123],\n",
      "         [-0.8312, -0.8164,  0.4807,  ..., -0.7041, -0.0211, -1.4034],\n",
      "         [-1.2361, -1.4920, -0.1493,  ..., -1.1058,  0.2150, -2.1550]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.7698, -0.7977,  2.4919,  ..., -0.4842,  0.2406,  0.3368],\n",
      "         [-1.3518, -0.6913,  1.5373,  ...,  0.4012,  0.8151, -0.3134],\n",
      "         [-1.1318, -0.9880,  1.2285,  ..., -0.9252, -0.2185, -0.2147],\n",
      "         ...,\n",
      "         [-1.2648, -0.1473,  0.2318,  ..., -0.7455,  0.7445, -1.1763],\n",
      "         [-1.1182, -0.7653,  0.5965,  ..., -0.8139, -0.1919, -0.5171],\n",
      "         [-1.7374, -1.5366,  0.0406,  ..., -1.3930,  0.4407, -1.2696]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.6875,  0.2041,  2.1748,  ...,  0.4021,  0.6755,  0.2871],\n",
      "         [-1.1140,  0.2715,  1.8182,  ...,  0.7089,  0.9393, -0.6513],\n",
      "         [-1.1808, -0.2111,  1.2145,  ..., -0.3062, -0.3527, -0.0283],\n",
      "         ...,\n",
      "         [-1.1291,  0.0094,  0.3396,  ..., -0.8593,  0.7301, -1.1360],\n",
      "         [-1.1479, -1.0628,  0.2736,  ..., -0.7807, -0.2073, -0.7164],\n",
      "         [-1.6424, -1.3972,  0.1036,  ..., -1.4584,  0.7468, -1.3374]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-1.3490, -0.2982,  1.3053,  ...,  0.8250,  0.2550, -0.0271],\n",
      "         [-0.7073,  0.1317,  1.2875,  ...,  0.9281,  1.1068, -0.7500],\n",
      "         [-1.1359, -0.1244,  0.5962,  ..., -0.2261, -0.8254, -0.4614],\n",
      "         ...,\n",
      "         [-0.7913, -0.4321,  0.0841,  ..., -1.0291,  0.7084, -1.6169],\n",
      "         [-0.9408, -1.6304,  0.1694,  ..., -0.6798, -0.1899, -1.2177],\n",
      "         [-1.5148, -1.6759,  0.0496,  ..., -1.3707,  0.8348, -1.6675]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n",
      "x.size(): torch.Size([1, 50, 3885])\n",
      "tensor([[[-0.8656, -0.9887,  1.0058,  ...,  1.3600,  0.4691, -0.4241],\n",
      "         [ 0.2489, -0.8225,  0.5389,  ...,  1.0018,  1.5167, -1.0560],\n",
      "         [-0.1840, -0.8894,  0.3202,  ..., -0.2020, -0.3834, -0.6816],\n",
      "         ...,\n",
      "         [-0.1357, -0.5034, -0.1739,  ..., -0.9705,  0.6671, -1.7410],\n",
      "         [-0.2846, -1.6656, -0.1010,  ..., -0.4728,  0.1436, -1.2896],\n",
      "         [-0.8684, -1.6634, -0.4291,  ..., -1.0892,  1.1341, -1.6564]]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "qkv.size(): torch.Size([1, 50, 11655])\n",
      "1, 50, 1, 3885\n",
      "qkv.size(): torch.Size([1, 50, 1, 11655])\n",
      "q.size(): torch.Size([1, 1, 50, 3885]), k.size(): torch.Size([1, 1, 50, 3885]), v.size(): torch.Size([1, 1, 50, 3885])\n",
      "values.size(): torch.Size([1, 1, 50, 3885]), attention.size(): torch.Size([1, 1, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "out = encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KMeans_Labels(X, n, rstate_limit, true_labels):\n",
    "    print(X)\n",
    "    # Specify the number of clusters (you can choose an appropriate value)\n",
    "    num_clusters = n\n",
    "    \n",
    "    # find centoids which give maximum purity\n",
    "    purity_collection = {}\n",
    "    for i in range(rstate_limit):\n",
    "        clusters = KMeans(n_init='auto', n_clusters=num_clusters, random_state=i, init='k-means++').fit(X).labels_\n",
    "        purity_collection[i] = Purity_Score(true_labels, clusters)\n",
    "    \n",
    "    max_rand_state = max(purity_collection, key=purity_collection.get)\n",
    "    print(f\"Maximum purity of {purity_collection[max_rand_state]} found on random state {max_rand_state}\")\n",
    "\n",
    "    # Create a KMeans model\n",
    "    kmeans = KMeans(n_init='auto', n_clusters=num_clusters, random_state=max_rand_state, init='k-means++')\n",
    "    # Fit the KMeans model to the TF-IDF data\n",
    "    kmeans.fit(X)\n",
    "    # Get the cluster assignments for each document\n",
    "    cluster_assignments = kmeans.labels_\n",
    "    \n",
    "    return cluster_assignments\n",
    "\n",
    "def Actual_Labels():\n",
    "    ReadDocuments(os.getcwd() + \"\\Doc50\")\n",
    "    actual_labels = {} # dictionary to store true assignments for each document | read sequence not followed\n",
    "    label_path = os.getcwd() + '\\\\Doc50 GT\\\\'\n",
    "    for labels_directory in os.listdir(label_path): # for each assignment folder\n",
    "        actual_cluster = int(labels_directory[1]) # extract cluster label from directory name\n",
    "        doc_labels = os.listdir(label_path + f\"\\\\{labels_directory}\") # for all document ids assigned to this cluster\n",
    "        for doc in doc_labels:\n",
    "            actual_labels[doc] = actual_cluster-1 # save cluster label\n",
    "    \n",
    "    label_seq = [] # save labels in order of documents read\n",
    "    for doc in doc_name:\n",
    "        label_seq.append(actual_labels[doc])\n",
    "    return label_seq\n",
    "\n",
    "def print_results(true_labels, predicted_labels, X):\n",
    "    print(\"RESULTS:\")\n",
    "    print(f\"Purity: {Purity_Score(true_labels, predicted_labels)}\")\n",
    "    print(f\"Silhouette Score: {silhouette_score(X, predicted_labels)}\")\n",
    "\n",
    "\n",
    "def wrapperFunction():\n",
    "    # ReadDocuments('Doc50')\n",
    "    vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', preprocessor=custom_preprocessor)\n",
    "    X = vectorizer.fit_transform(doc_content)\n",
    "\n",
    "    SaveFeatures(X, 'DOC50_TFIDF_Features.pkl')\n",
    "    \n",
    "    true_labels = Actual_Labels()\n",
    "    predicted_labels = KMeans_Labels(X, 5, 1500, true_labels)\n",
    "    Evaluate(X, true_labels, predicted_labels)\n",
    "    return predicted_labels, X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_x = out.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 3885)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enhanced_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_content = []  # all the content in the document\n",
    "doc_name = []  # name of the document\n",
    "files_path = []  # path to the documents\n",
    "lexical_chain = []  # list of lexical chains from each document\n",
    "total_features = []  # total number of features. 1652\n",
    "final_training_Features = []\n",
    "corpus = []\n",
    "doc_list_sequence = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07043584 -0.4605227   0.3678442  ...  1.117732   -0.37223384\n",
      "   0.02894631]\n",
      " [ 0.79605615 -0.6738356   0.48651254 ...  0.63497174  0.433036\n",
      "  -0.7865405 ]\n",
      " [-0.13338403 -0.6083789  -0.11183209 ... -0.24193646 -1.0200937\n",
      "  -0.51656073]\n",
      " ...\n",
      " [-0.35077035 -0.10367109 -0.7955016  ... -0.84621     0.03775709\n",
      "  -2.2199671 ]\n",
      " [-0.641953   -1.2674987  -0.7170792  ... -0.22117291 -0.24665022\n",
      "  -1.6835128 ]\n",
      " [-0.8173722  -0.8955151  -1.0286976  ... -1.082792    0.6256592\n",
      "  -2.005139  ]]\n",
      "Maximum purity of 0.78 found on random state 142\n"
     ]
    }
   ],
   "source": [
    "true_labels = Actual_Labels()\n",
    "pred_lables = KMeans_Labels(enhanced_x[0], 5, 700, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.78\n",
      "Silhouette Score: 0.01145158987492323\n",
      "ARI Score: 0.6034407559970923\n",
      "NMI Score: 0.7665762273140948\n"
     ]
    }
   ],
   "source": [
    "Evaluate(enhanced_x[0], true_labels, pred_lables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
